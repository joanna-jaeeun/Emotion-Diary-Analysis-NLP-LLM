{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a10c1dd",
   "metadata": {},
   "source": [
    "# NLP and LLM-based Analysis of Student Emotion Diaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb343b",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b02ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import moduels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from openai import OpenAI\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "import neo4j\n",
    "from neo4j_graphrag.generation.prompts import ERExtractionTemplate\n",
    "from neo4j_graphrag.experimental.components.kg_writer import Neo4jWriter\n",
    "from neo4j_graphrag.experimental.components.types import Neo4jGraph\n",
    "\n",
    "import torch\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "from transformers import AutoTokenizer, AutoModelForAudioClassification, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "plt.rcParams['font.family'] = 'AppleGothic' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c27b24",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21030b5f",
   "metadata": {},
   "source": [
    "### Digitalization - Google AI Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3864b49",
   "metadata": {},
   "source": [
    "### Constructing Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35454e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open text data\n",
    "with open('raw_data.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# Devide text by name\n",
    "blocks = re.split(r'\\n(?=[가-힣]{2,4}\\n일기 \\d+\\n)',raw_text) #re.split(pattern, string)\n",
    "\n",
    "rows = []\n",
    "word = []\n",
    "\n",
    "for block in blocks :\n",
    "    word.append(str.split(block, '\\n'))\n",
    "\n",
    "# Create Dataframe\n",
    "raw_data = pd.DataFrame(columns=['Name', 'Number', 'Date', 'Weather', 'Emotion', 'Diary title' ,'Diary'])\n",
    "\n",
    "# Extract componets from each dairy entry and insert them into dataframe(raw_data)\n",
    "def extract_value(text, prefix):\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix):].strip()\n",
    "    return ''\n",
    "\n",
    "\n",
    "for row in word:\n",
    "\n",
    "    name = row[0]\n",
    "    number = row[1]\n",
    "\n",
    "\n",
    "    date = ''\n",
    "    weather = ''\n",
    "    emotion = ''\n",
    "    title = ''\n",
    "    diary_text = ''\n",
    "\n",
    "    for text in row:\n",
    "        if text.startswith('날짜:'):\n",
    "            date = extract_value(text, '날짜:')\n",
    "        elif text.startswith('날씨:'):\n",
    "            weather = extract_value(text, '감정:')\n",
    "        elif text.startswith('감정:'):\n",
    "            emotion = extract_value(text, '감정:')\n",
    "        elif text.startswith('제목:'):\n",
    "            title = extract_value(text, '제목:')\n",
    "        elif text.startswith('내용:'):\n",
    "            diary_text = extract_value(text, '내용:')\n",
    "\n",
    "    raw_data.loc[len(raw_data)] = [name, number, date, weather, emotion, title, diary_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c475a",
   "metadata": {},
   "source": [
    "### Data Privacy\n",
    "- hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af339228",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To protect data privacy, students' names have been replaced with nicknames.\n",
    "\n",
    "# Students real name list\n",
    "students_real_names = list(raw_data['Name'].unique())\n",
    "\n",
    "# Get full name and surname\n",
    "name_variants = []\n",
    "for name in students_real_names:\n",
    "    if len(name) > 1:\n",
    "        # Full name\n",
    "        name_variants.append(name)\n",
    "        # First name (My students’ first names start with the initial letter of their surname.)\n",
    "        name_variants.append(name[1:])\n",
    "    else:\n",
    "        name_variants.append(name)\n",
    "\n",
    "#Generate nicknames using hashlib\n",
    "def hash_string(input_str):\n",
    "    return hashlib.sha256(input_str.encode()).hexdigest()[:7]\n",
    "\n",
    "nicknames = [hash_string(students_real_names[i]) for i in range(len(students_real_names))]\n",
    "\n",
    "# name - nick name mapping\n",
    "nickname_map = {}\n",
    "for real_name, nick in zip(students_real_names, nicknames):\n",
    "    nickname_map[real_name] = nick\n",
    "    if len(real_name) > 1:\n",
    "        nickname_map[real_name[1:]] = nick\n",
    "\n",
    "# nickname_map eg : {real name : nickname}\n",
    "\n",
    "\n",
    "# The 'Name' and 'Diary' columns contain real names.\n",
    "# Transform all real names into nicknames for privacy.\n",
    "\n",
    "df_privacy = raw_data.copy()\n",
    "\n",
    "# Define function\n",
    "def replace_names(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    # change serveral names using regular expressions\n",
    "\n",
    "    # mapping dictionary\n",
    "    adjusted_map = {\n",
    "        ('**' if k == '*' else k): v for k, v in nickname_map.items()  #One student has one letter of lastname, so it counfused\n",
    "    }\n",
    "\n",
    "    # regular expression\n",
    "    pattern = re.compile(\"|\".join(re.escape(k) for k in adjusted_map.keys()))\n",
    "\n",
    "    # change function\n",
    "    return pattern.sub(lambda x: adjusted_map[x.group()], text)\n",
    "\n",
    "\n",
    "# Diary columns\n",
    "df_privacy['Diary'] = df_privacy['Diary'].apply(replace_names)\n",
    "\n",
    "# Name coulums\n",
    "df_privacy['Name'] = df_privacy['Name'].map(nickname_map).fillna(df_privacy['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a83997c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Diary title</th>\n",
       "      <th>Diary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>행복하다, 기쁘다</td>\n",
       "      <td>그림</td>\n",
       "      <td>오늘 미술시간에 그림을 그리는데 처음 스케치할 때는 친구들이 별로 말을 안 했는데 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>즐겁다, 답답하다(다음에 또 하고 싶다)</td>\n",
       "      <td>오목</td>\n",
       "      <td>오늘은 오목을 했다. 2aa8348강 나랑 먼저 하고 다음은 826175f이랑 나랑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 3</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td></td>\n",
       "      <td>속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 생존수영을 배웠다. 근데 dc88476이가 벽에 안 붙어서 두 번 말했는데 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 4</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td></td>\n",
       "      <td>무섭다, 울고 싶다, 긴장하다</td>\n",
       "      <td>놀람</td>\n",
       "      <td>오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Number        Date Weather                              Emotion  \\\n",
       "11  71db26b   일기 1                                                행복하다, 기쁘다   \n",
       "12  71db26b   일기 2                                   즐겁다, 답답하다(다음에 또 하고 싶다)   \n",
       "13  71db26b   일기 3  2025-07-07          속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다   \n",
       "14  71db26b   일기 4  2025-07-08                             무섭다, 울고 싶다, 긴장하다   \n",
       "\n",
       "   Diary title                                              Diary  \n",
       "11          그림  오늘 미술시간에 그림을 그리는데 처음 스케치할 때는 친구들이 별로 말을 안 했는데 ...  \n",
       "12          오목  오늘은 오목을 했다. 2aa8348강 나랑 먼저 하고 다음은 826175f이랑 나랑...  \n",
       "13        생존수영  오늘은 생존수영을 배웠다. 근데 dc88476이가 벽에 안 붙어서 두 번 말했는데 ...  \n",
       "14          놀람  오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_privacy[11:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a5e13",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4276470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diary = df_privacy.copy()\n",
    "# Remove rows with missing emotion values by index\n",
    "diary.drop(index=[8, 205, 210], inplace=True)\n",
    "\n",
    "\n",
    "# For some rows with missing emotions, infer emotion from the first word of 'Diary title'\n",
    "for idx in diary.iloc[190:200].index:\n",
    "    diary.loc[idx, 'Emotion'] = diary.loc[idx, \"Diary title\"].split(\" \")[0]\n",
    "\n",
    "# diary.loc[190:199, 'Emotion'] = diary.loc[190:199, 'Diary title'].apply(lambda x: x.strip()[0])\n",
    "\n",
    "# Reset the index to remove gaps and have consecutive numbering\n",
    "diary.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f2fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 257 entries, 0 to 256\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Name         257 non-null    object\n",
      " 1   Number       257 non-null    object\n",
      " 2   Date         257 non-null    object\n",
      " 3   Weather      257 non-null    object\n",
      " 4   Emotion      257 non-null    object\n",
      " 5   Diary title  257 non-null    object\n",
      " 6   Diary        257 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "diary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2d5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dac2109 : 오늘은 4교시에 체육을 했다. 피구팀을 정했는데 2aa8348팀이 안돼서 아쉬웠지만 즐거웠다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peer relationships are one of the most influential factors affecting students' emotions in school life.\n",
    "\n",
    "student_names = list(diary.Name.unique())\n",
    "student_names\n",
    "\n",
    "# Select only diary entries that contain students' names to maximize analysis efficiency\n",
    "pattern = '|'.join(map(re.escape, student_names))\n",
    "diary2 = diary[diary['Diary'].str.contains(pattern, na= False)]\n",
    "# Only 38 diary entries left\n",
    "diary2\n",
    "\n",
    "# Change text format for Neo4j input\n",
    "text_list = []\n",
    "for idx, row in diary2.iterrows() :\n",
    "    text_list.append(row['Name'] + \" : \" + row['Diary'])\n",
    "text_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086d52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env file\n",
    "load_dotenv()\n",
    "\n",
    "# API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0ab2a",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516349ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ERExtractionTemplate()\n",
    "llm = OpenAILLM(model_name=\"gpt-4o\", model_params={\"temperature\": 0})\n",
    "\n",
    "graph_json = ''\n",
    "graph_history = ''\n",
    "for user_input in text_list + ['finish']:\n",
    "    if(user_input == 'finish'):\n",
    "        with neo4j.GraphDatabase.driver(\"bolt://44.199.251.177:7687\", auth=(\"neo4j\", 'tune-disk-rain')) as driver:\n",
    "            writer = Neo4jWriter(driver)\n",
    "            graph = Neo4jGraph(\n",
    "                nodes= graph_json['nodes'],\n",
    "                relationships= graph_json['relationships']\n",
    "            )\n",
    "            await writer.run(graph)\n",
    "            break\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        schema = \"\"\"\n",
    "        '0f368b7', '71db26b', '3a693a0', 'dac2109', 'dc88476', 'f14a686', '2aa8348', '7685386', '826175f', '1668616', '2040613', 'e0dabba',\n",
    "       '58931c4', '6a4eec6', 'd43e7e4', '23de8b0', '2926bfc', '45156c0', '8fcaf23', '9909af3', '9642e41', 'ec4a490', 'a2424b0', 'd9a5b82', '6c632a1'\n",
    "        These are student name\n",
    "        All 25 student nodes must always appear \"\"\",\n",
    "        text = user_input\n",
    "            + \"\"\"(Continue extracting the graph for the following Input text.\n",
    "                Ensure you retain the existing nodes and relationships from the graph history\n",
    "                and add only new nodes and relationships.\\n\n",
    "                Graph History : \"\"\" + graph_history + \")\",\n",
    "        examples = ''\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "    response = llm.invoke(prompt) # Extrach graph\n",
    "    print(response.content)\n",
    "    graph_history = response.content\n",
    "\n",
    "    # Sometimes the response includes ```json```, so we split based on {}\n",
    "    graph_json = json.loads(graph_history[graph_history.find(\"{\"):graph_history.rfind(\"}\")+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73723b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the outcome at Neo4j Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7a676",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f6acc",
   "metadata": {},
   "source": [
    "### Psedo-Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8882f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.855, 0.963],\n",
       " [0.855, 0.963],\n",
       " [-0.652, -0.614],\n",
       " [0.973, 0.96, 0.855, 0.963, 0.844],\n",
       " [-0.599, -0.912],\n",
       " [0.977, 0.96, 0.963],\n",
       " [0.973, 0.96, 0.855, 0.963],\n",
       " [0.977, 0.96, 0.855, 0.963],\n",
       " [-0.599],\n",
       " [0.963]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"sangrimlee/bert-base-multilingual-cased-nsmc\", framework='pt')\n",
    "\n",
    "# Manually correct the mislabeled data\n",
    "# negative_words dictionary\n",
    "negative_words = [\"슬프\", \"아쉽\", \"아쉬\", \"화나다\", \"울고\", \"무섭\", \"긴장\", \"귀찮\", \"떨리다\", \"아프\", \"외롭\"]\n",
    "# positive_words dictionary\n",
    "positive_words = [\"상상\", \"궁금\", \"신난\", \"뿌듯\", \"흐뭇\", \"즐겁\", \"신기\", \"소망\", \"감사\"]\n",
    "nutural_words = [\"그저\", \"그렇다\"]\n",
    "\n",
    "# Get the scores for each emotion words\n",
    "def get_score_morphs(df, tag_colname):\n",
    "    all_scores = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        sentence = df[tag_colname][i]\n",
    "        score = []\n",
    "        # To get the scores for each emotion word, split the text using commas\n",
    "        for part in sentence.split(\",\"):\n",
    "            part_clean = part.strip()\n",
    "            result = classifier(part_clean)[0]\n",
    "            # If the word is in the emotion dictionary(negative), treat it as negative.\n",
    "            if any(neg_word in part_clean for neg_word in negative_words):\n",
    "                adjusted_score = round(-abs(result['score']), 3)\n",
    "\n",
    "            # If the word is in the emotion dictionary(negative), treat it as negative.\n",
    "            elif any(pos_word in part_clean for pos_word in positive_words):\n",
    "                adjusted_score = round(abs(result['score']), 3)\n",
    "            else:\n",
    "                # normal\n",
    "                if result['label'].lower() == 'negative':\n",
    "                    adjusted_score = round(-result['score'], 3)\n",
    "                else:\n",
    "                    adjusted_score = round(result['score'], 3)\n",
    "            score.append(adjusted_score)\n",
    "        all_scores.append(score)\n",
    "    return all_scores\n",
    "\n",
    "scores = get_score_morphs(diary, \"Emotion\")\n",
    "scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd3b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "\n",
    "diary_label = diary.copy()\n",
    "def label_from_scores(all_scores):\n",
    "    for i in range(len(all_scores)):\n",
    "        all_positive = all(n > 0 for n in all_scores[i])\n",
    "        all_negative = all(n < 0 for n in all_scores[i])\n",
    "\n",
    "        # If all words are positive, label as 1\n",
    "        if all_positive :\n",
    "            label = 1\n",
    "        # If all words are negative, label as 0\n",
    "        elif all_negative :\n",
    "            label = 0\n",
    "        # If positive and negative are mixed, choose the one with the higher absolute value\n",
    "        else :\n",
    "            max_abs_num = max(all_scores[i], key = abs)\n",
    "            lable =  1 if max_abs_num > 0 else 0\n",
    "\n",
    "        diary_label.loc[i, 'label'] = label\n",
    "    return diary_label\n",
    "\n",
    "diary_label = label_from_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e7294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Diary title</th>\n",
       "      <th>Diary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>즐겁다, 답답하다(다음에 또 하고 싶다)</td>\n",
       "      <td>오목</td>\n",
       "      <td>오늘은 오목을 했다. 2aa8348강 나랑 먼저 하고 다음은 826175f이랑 나랑...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 3</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td></td>\n",
       "      <td>속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 생존수영을 배웠다. 근데 dc88476이가 벽에 안 붙어서 두 번 말했는데 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 4</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td></td>\n",
       "      <td>무섭다, 울고 싶다, 긴장하다</td>\n",
       "      <td>놀람</td>\n",
       "      <td>오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>71db26b</td>\n",
       "      <td>일기 5</td>\n",
       "      <td>2025-07-09</td>\n",
       "      <td></td>\n",
       "      <td>행복하다, 설레다, 재미있다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 구명조끼 배우기를 했다. 단계는 1, 2, 3, 4, 5, 6단계가 있었다....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Number        Date Weather                              Emotion  \\\n",
       "11  71db26b   일기 2                                   즐겁다, 답답하다(다음에 또 하고 싶다)   \n",
       "12  71db26b   일기 3  2025-07-07          속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다   \n",
       "13  71db26b   일기 4  2025-07-08                             무섭다, 울고 싶다, 긴장하다   \n",
       "14  71db26b   일기 5  2025-07-09                              행복하다, 설레다, 재미있다   \n",
       "\n",
       "   Diary title                                              Diary  label  \n",
       "11          오목  오늘은 오목을 했다. 2aa8348강 나랑 먼저 하고 다음은 826175f이랑 나랑...    1.0  \n",
       "12        생존수영  오늘은 생존수영을 배웠다. 근데 dc88476이가 벽에 안 붙어서 두 번 말했는데 ...    0.0  \n",
       "13          놀람  오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...    0.0  \n",
       "14        생존수영  오늘은 구명조끼 배우기를 했다. 단계는 1, 2, 3, 4, 5, 6단계가 있었다....    1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary_label[11:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a108fec0",
   "metadata": {},
   "source": [
    "### Sentiment Anaysis - BERT (Pretrained model VS Fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f40f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1.0    173\n",
       "0.0     84\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the ratio\n",
    "diary_label['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138bdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = diary_label[['Diary', 'label']].sample(frac = 0.8, random_state = 42)\n",
    "test_data = diary_label[['Diary', 'label']].drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43485a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5882352941176471, F1: 0.7407407407407407, Precision: 0.5882352941176471, Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Pretrained model\n",
    "\n",
    "# Load model\n",
    "model_name = \"beomi/KcELECTRA-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Create pipeline(text classification)\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Classification\n",
    "results = []\n",
    "for idx, row in test_data.iterrows() :\n",
    "    result = classifier(row['Diary'])[0].get(\"label\")\n",
    "    results.append(result)\n",
    "\n",
    "# # Correct the label format\n",
    "test_data['prediction'] = results\n",
    "test_data['pre_trained_label'] = test_data['prediction'].apply(lambda x : 0 if x == 'LABEL_0' else 1)\n",
    "test_data.drop(['prediction'], axis = 1)\n",
    "\n",
    "# Evaluation\n",
    "y_true = test_data['label'] #real\n",
    "y_pred = test_data['pre_trained_label'] #predict\n",
    "\n",
    "acc = accuracy_score (y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc}, F1: {f1}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c96e62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Fine tuning\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device :', device)\n",
    "\n",
    "model_name = \"beomi/KcELECTRA-base\"\n",
    "\n",
    "# Tokenising\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenized_train_sentences = tokenizer(\n",
    "    list(train_data['Diary']),\n",
    "    return_tensors = \"pt\",\n",
    "    max_length = 128,\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    add_special_tokens = True)\n",
    "\n",
    "tokenized_test_sentences = tokenizer(\n",
    "    list(test_data['Diary']),\n",
    "    return_tensors = \"pt\",\n",
    "    max_length = 128,\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    add_special_tokens = True)\n",
    "\n",
    "# Load Dataset\n",
    "class CurseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_label= train_data[\"label\"].values\n",
    "test_label=test_data[\"label\"].values\n",
    "\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n",
    "\n",
    "# Training\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 2)\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './',\n",
    "    num_train_epochs= 3,\n",
    "    per_device_train_batch_size= 16,\n",
    "    per_device_eval_batch_size= 64,\n",
    "    logging_dir = '.logs',\n",
    "    logging_steps = 5,\n",
    "    save_total_limit = 2,\n",
    "    report_to=[\"none\"]\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "def compute_metrics(pred) :\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _  = precision_recall_fscore_support(labels, preds, average = 'binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy_score' : acc,\n",
    "        'f1': f1,\n",
    "        'precision' : precision,\n",
    "        'recall' : recall\n",
    "    }\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eb6d463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebda67f2dbb4e3b9471743b15028502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6734, 'grad_norm': 1.3268693685531616, 'learning_rate': 4.358974358974359e-05, 'epoch': 0.38}\n",
      "{'loss': 0.5843, 'grad_norm': 1.0392886400222778, 'learning_rate': 3.717948717948718e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5882, 'grad_norm': 2.93300724029541, 'learning_rate': 3.0769230769230774e-05, 'epoch': 1.15}\n",
      "{'loss': 0.5353, 'grad_norm': 1.8883098363876343, 'learning_rate': 2.435897435897436e-05, 'epoch': 1.54}\n",
      "{'loss': 0.4972, 'grad_norm': 1.7386845350265503, 'learning_rate': 1.794871794871795e-05, 'epoch': 1.92}\n",
      "{'loss': 0.3966, 'grad_norm': 2.353531837463379, 'learning_rate': 1.153846153846154e-05, 'epoch': 2.31}\n",
      "{'loss': 0.4649, 'grad_norm': 6.351107120513916, 'learning_rate': 5.128205128205128e-06, 'epoch': 2.69}\n",
      "{'train_runtime': 24.9872, 'train_samples_per_second': 24.733, 'train_steps_per_second': 1.561, 'train_loss': 0.5166922991092389, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=0.5166922991092389, metrics={'train_runtime': 24.9872, 'train_samples_per_second': 24.733, 'train_steps_per_second': 1.561, 'total_flos': 23818744953000.0, 'train_loss': 0.5166922991092389, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88a78955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a490211b5b2b4447acedb05d0939a939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5271451473236084,\n",
       " 'eval_accuracy_score': 0.7843137254901961,\n",
       " 'eval_f1': 0.835820895522388,\n",
       " 'eval_precision': 0.7567567567567568,\n",
       " 'eval_recall': 0.9333333333333333,\n",
       " 'eval_runtime': 0.7853,\n",
       " 'eval_samples_per_second': 64.945,\n",
       " 'eval_steps_per_second': 1.273,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset = test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45359f8",
   "metadata": {},
   "source": [
    "## Generating products (Prompt engineering)\n",
    "- using GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diary_LLM = diary_label.copy()\n",
    "\n",
    "# Sentiment analysis and finding cause of the emotion\n",
    "\n",
    "def analyze_emotion_and_cause(text):\n",
    "    # 1. Sentiment analysis\n",
    "    emotion_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\n",
    "             \"Detect one or more emotions present in the input text and provide a score (e.g., from 0 to 1) indicating the intensity or confidence level for each detected emotion. \"\n",
    "             \"Choose only from the following emotions: neutral, happy, joy, sadness, anger, worry. \"\n",
    "             \"Example output format: {\\\"happy\\\": 0.8 , \\\"worry\\\": 0.6}\"},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    emotion_text = emotion_response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        # Parsing with dictionary\n",
    "        emotion_dict = json.loads(emotion_text)\n",
    "    except:\n",
    "        print(\"Emotion parsing error:\", emotion_text)\n",
    "        return {}, {}\n",
    "\n",
    "    # 2. Finding cause of the emotion\n",
    "    cause_prompt = f\"\"\"\n",
    "    Given the following sentence and detected emotions, explain the cause for each emotion.\n",
    "    Sentence: \"{text}\"\n",
    "    Detected Emotions: {emotion_dict}\n",
    "\n",
    "    Format your answer as a JSON dictionary mapping each emotion to its cause. Don't forget comma in JSON dictionary\n",
    "    Example:\n",
    "\n",
    "   {{\"happy\": \"being able to play with Student14\", \"worry\": \"not being able to play with Student14\"}}\n",
    "    Answer in English only.\n",
    "    \"\"\"\n",
    "    cause_response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": cause_prompt}\n",
    "        ]\n",
    "    )\n",
    "    cause_text = cause_response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        cause_dict = json.loads(cause_text)\n",
    "    except:\n",
    "        print(\"Cause parsing error:\", cause_text)\n",
    "        return emotion_dict, {}\n",
    "\n",
    "    return emotion_dict, cause_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 'emotion' and 'emotion_cause' columns in the dataframe\n",
    "emotion_results = []\n",
    "cause_results = []\n",
    "#\n",
    "for diary_text in diary_LLM['Diary']:\n",
    "    try:\n",
    "        emotion, cause = analyze_emotion_and_cause(diary_text)\n",
    "    except Exception as e:\n",
    "        emotion, cause = \"error\", str(e)\n",
    "\n",
    "    emotion_results.append(emotion)\n",
    "    cause_results.append(cause)\n",
    "\n",
    "#\n",
    "diary_LLM['emotion'] = emotion_results\n",
    "diary_LLM['emotion_cause'] = cause_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30c3e7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Diary_title</th>\n",
       "      <th>Diary</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>즐겁다, 답답하다(다음에 또 하고 싶다)</td>\n",
       "      <td>오목</td>\n",
       "      <td>오늘은 오목을 했다. 8a2b9ef강 나랑 먼저 하고 다음은 91ab0aa이랑 나랑...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neutral': 1.0}</td>\n",
       "      <td>{'neutral': \"The speaker is describing a serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 3</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 생존수영을 배웠다. 근데 6ee5fe2이가 벽에 안 붙어서 두 번 말했는데 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'anger': 0.8, 'sadness': 0.7, 'worry': 0.4}</td>\n",
       "      <td>{'anger': \"Feeling frustrated because the pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 4</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>무섭다, 울고 싶다, 긴장하다</td>\n",
       "      <td>놀람</td>\n",
       "      <td>오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'worry': 0.9, 'sadness': 0.7}</td>\n",
       "      <td>{'worry': 'The cause of worry in the sentence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 5</td>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>행복하다, 설레다, 재미있다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 구명조끼 배우기를 했다. 단계는 1, 2, 3, 4, 5, 6단계가 있었다....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neutral': 0.9, 'joy': 0.2, 'worry': 0.4}</td>\n",
       "      <td>{'neutral': 'Learning how to wear a life jacke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Number        Date  Weather                              Emotion  \\\n",
       "11  753e216   일기 2         NaN      NaN               즐겁다, 답답하다(다음에 또 하고 싶다)   \n",
       "12  753e216   일기 3  2025-07-07      NaN  속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다   \n",
       "13  753e216   일기 4  2025-07-08      NaN                     무섭다, 울고 싶다, 긴장하다   \n",
       "14  753e216   일기 5  2025-07-09      NaN                      행복하다, 설레다, 재미있다   \n",
       "\n",
       "   Diary_title                                              Diary  label  \\\n",
       "11          오목  오늘은 오목을 했다. 8a2b9ef강 나랑 먼저 하고 다음은 91ab0aa이랑 나랑...    1.0   \n",
       "12        생존수영  오늘은 생존수영을 배웠다. 근데 6ee5fe2이가 벽에 안 붙어서 두 번 말했는데 ...    0.0   \n",
       "13          놀람  오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...    0.0   \n",
       "14        생존수영  오늘은 구명조끼 배우기를 했다. 단계는 1, 2, 3, 4, 5, 6단계가 있었다....    1.0   \n",
       "\n",
       "                                         emotion  \\\n",
       "11                              {'neutral': 1.0}   \n",
       "12  {'anger': 0.8, 'sadness': 0.7, 'worry': 0.4}   \n",
       "13                {'worry': 0.9, 'sadness': 0.7}   \n",
       "14    {'neutral': 0.9, 'joy': 0.2, 'worry': 0.4}   \n",
       "\n",
       "                                        emotion_cause  \n",
       "11  {'neutral': \"The speaker is describing a serie...  \n",
       "12  {'anger': \"Feeling frustrated because the pers...  \n",
       "13  {'worry': 'The cause of worry in the sentence ...  \n",
       "14  {'neutral': 'Learning how to wear a life jacke...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary_LLM[11:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53a2931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diary_LLM2 = diary_LLM.copy()\n",
    "\n",
    "# Ready for adding emotion scores\n",
    "\n",
    "columns = ['neutral', 'happy', 'joy', 'sadness', 'anger', 'worry']\n",
    "zero = pd.DataFrame(0, index=range(257), columns=columns)\n",
    "\n",
    "diary_LLM2 = pd.concat([diary_LLM2, zero],  axis = 1)\n",
    "\n",
    "\n",
    "# Fill in the value if the corresponding key exists in the emotion dictionary for each emotion.\n",
    "emotion_keys = ['happy', 'worry', 'joy', 'sadness', 'anger', 'neutral']\n",
    "\n",
    "for key in emotion_keys:\n",
    "    diary_LLM2[key] = diary_LLM2.apply(lambda row: row['emotion'].get(key) if pd.notnull(row['emotion']) and isinstance(row['emotion'], dict) else None, axis=1)\n",
    "\n",
    "# Fillna\n",
    "diary_LLM2[['happy', 'worry', 'joy', 'sadness', 'anger', 'neutral']] = \\\n",
    "    diary_LLM2[['happy', 'worry', 'joy', 'sadness', 'anger', 'neutral']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ced4144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Diary_title</th>\n",
       "      <th>Diary</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_cause</th>\n",
       "      <th>neutral</th>\n",
       "      <th>happy</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>즐겁다, 답답하다(다음에 또 하고 싶다)</td>\n",
       "      <td>오목</td>\n",
       "      <td>오늘은 오목을 했다. 8a2b9ef강 나랑 먼저 하고 다음은 91ab0aa이랑 나랑...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neutral': 1.0}</td>\n",
       "      <td>{'neutral': \"The speaker is describing a serie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 3</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 생존수영을 배웠다. 근데 6ee5fe2이가 벽에 안 붙어서 두 번 말했는데 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'anger': 0.8, 'sadness': 0.7, 'worry': 0.4}</td>\n",
       "      <td>{'anger': \"Feeling frustrated because the pers...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 4</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>무섭다, 울고 싶다, 긴장하다</td>\n",
       "      <td>놀람</td>\n",
       "      <td>오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'worry': 0.9, 'sadness': 0.7}</td>\n",
       "      <td>{'worry': 'The cause of worry in the sentence ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 5</td>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>행복하다, 설레다, 재미있다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 구명조끼 배우기를 했다. 단계는 1, 2, 3, 4, 5, 6단계가 있었다....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neutral': 0.9, 'joy': 0.2, 'worry': 0.4}</td>\n",
       "      <td>{'neutral': 'Learning how to wear a life jacke...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Number        Date  Weather                              Emotion  \\\n",
       "11  753e216   일기 2         NaN      NaN               즐겁다, 답답하다(다음에 또 하고 싶다)   \n",
       "12  753e216   일기 3  2025-07-07      NaN  속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다   \n",
       "13  753e216   일기 4  2025-07-08      NaN                     무섭다, 울고 싶다, 긴장하다   \n",
       "14  753e216   일기 5  2025-07-09      NaN                      행복하다, 설레다, 재미있다   \n",
       "\n",
       "   Diary_title                                              Diary  label  \\\n",
       "11          오목  오늘은 오목을 했다. 8a2b9ef강 나랑 먼저 하고 다음은 91ab0aa이랑 나랑...    1.0   \n",
       "12        생존수영  오늘은 생존수영을 배웠다. 근데 6ee5fe2이가 벽에 안 붙어서 두 번 말했는데 ...    0.0   \n",
       "13          놀람  오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...    0.0   \n",
       "14        생존수영  오늘은 구명조끼 배우기를 했다. 단계는 1, 2, 3, 4, 5, 6단계가 있었다....    1.0   \n",
       "\n",
       "                                         emotion  \\\n",
       "11                              {'neutral': 1.0}   \n",
       "12  {'anger': 0.8, 'sadness': 0.7, 'worry': 0.4}   \n",
       "13                {'worry': 0.9, 'sadness': 0.7}   \n",
       "14    {'neutral': 0.9, 'joy': 0.2, 'worry': 0.4}   \n",
       "\n",
       "                                        emotion_cause  neutral  happy  joy  \\\n",
       "11  {'neutral': \"The speaker is describing a serie...        0      0    0   \n",
       "12  {'anger': \"Feeling frustrated because the pers...        0      0    0   \n",
       "13  {'worry': 'The cause of worry in the sentence ...        0      0    0   \n",
       "14  {'neutral': 'Learning how to wear a life jacke...        0      0    0   \n",
       "\n",
       "    sadness  anger  worry  \n",
       "11        0      0      0  \n",
       "12        0      0      0  \n",
       "13        0      0      0  \n",
       "14        0      0      0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary_LLM2[11:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "462bbf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 257 entries, 0 to 256\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Name           257 non-null    object \n",
      " 1   Number         257 non-null    object \n",
      " 2   Date           208 non-null    object \n",
      " 3   Weather        0 non-null      float64\n",
      " 4   Emotion        257 non-null    object \n",
      " 5   Diary_title    159 non-null    object \n",
      " 6   Diary          257 non-null    object \n",
      " 7   label          257 non-null    float64\n",
      " 8   emotion        257 non-null    object \n",
      " 9   emotion_cause  257 non-null    object \n",
      " 10  neutral        257 non-null    int64  \n",
      " 11  happy          257 non-null    int64  \n",
      " 12  joy            257 non-null    int64  \n",
      " 13  sadness        257 non-null    int64  \n",
      " 14  anger          257 non-null    int64  \n",
      " 15  worry          257 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(8)\n",
      "memory usage: 32.3+ KB\n"
     ]
    }
   ],
   "source": [
    "diary_LLM2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dominant emotion dataframe\n",
    "diary_LLM3 = diary_LLM2.copy()\n",
    "emotion_cols = [\"neutral\", \"happy\", \"joy\", \"anger\", \"sadness\", \"worry\"]\n",
    "\n",
    "diary_LLM3[\"dominant_emotion\"] = diary_LLM3[emotion_cols].idxmax(axis=1)  \n",
    "diary_LLM3[\"dominant_score\"] = diary_LLM3[emotion_cols].max(axis=1) \n",
    "diary_LLM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6b289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1518b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Diary_title</th>\n",
       "      <th>Diary</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_cause</th>\n",
       "      <th>neutral</th>\n",
       "      <th>happy</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>worry</th>\n",
       "      <th>dominant_emotion</th>\n",
       "      <th>dominant_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>즐겁다, 답답하다(다음에 또 하고 싶다)</td>\n",
       "      <td>오목</td>\n",
       "      <td>오늘은 오목을 했다. 8a2b9ef강 나랑 먼저 하고 다음은 91ab0aa이랑 나랑...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neutral': 1.0}</td>\n",
       "      <td>{'neutral': \"The speaker is describing a serie...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 3</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>속상하다, 화나다, 억울하다, 기분이 나쁘다, 화가 부글부글한다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 생존수영을 배웠다. 근데 6ee5fe2이가 벽에 안 붙어서 두 번 말했는데 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'anger': 0.8, 'sadness': 0.7, 'worry': 0.4}</td>\n",
       "      <td>{'anger': \"Feeling frustrated because the pers...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 4</td>\n",
       "      <td>2025-07-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>무섭다, 울고 싶다, 긴장하다</td>\n",
       "      <td>놀람</td>\n",
       "      <td>오늘은 새우등 뜨기랑 해파리 뜨기랑 페트병 들고 뜨기를 했는데 너무 무서워서 훌쩍이...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'worry': 0.9, 'sadness': 0.7}</td>\n",
       "      <td>{'worry': 'The cause of worry in the sentence ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>worry</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>753e216</td>\n",
       "      <td>일기 5</td>\n",
       "      <td>2025-07-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>행복하다, 설레다, 재미있다</td>\n",
       "      <td>생존수영</td>\n",
       "      <td>오늘은 구명조끼 배우기를 했다. 단계는 1, 2, 3, 4, 5, 6단계가 있었다....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neutral': 0.9, 'joy': 0.2, 'worry': 0.4}</td>\n",
       "      <td>{'neutral': 'Learning how to wear a life jacke...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name Number        Date  ...  worry dominant_emotion dominant_score\n",
       "11  753e216   일기 2         NaN  ...    0.0          neutral            1.0\n",
       "12  753e216   일기 3  2025-07-07  ...    0.4            anger            0.8\n",
       "13  753e216   일기 4  2025-07-08  ...    0.9            worry            0.9\n",
       "14  753e216   일기 5  2025-07-09  ...    0.4          neutral            0.9\n",
       "\n",
       "[4 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dominant emotion dataframe -> generate emotion calendar\n",
    "diary_LLM3 = diary_LLM2.copy()\n",
    "emotion_cols = [\"neutral\", \"happy\", \"joy\", \"anger\", \"sadness\", \"worry\"]\n",
    "\n",
    "diary_LLM3[\"dominant_emotion\"] = diary_LLM3[emotion_cols].idxmax(axis=1)  \n",
    "diary_LLM3[\"dominant_score\"] = diary_LLM3[emotion_cols].max(axis=1) \n",
    "diary_LLM3[11:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73457a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 257 entries, 0 to 256\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Name              257 non-null    object \n",
      " 1   Number            257 non-null    object \n",
      " 2   Date              208 non-null    object \n",
      " 3   Weather           0 non-null      float64\n",
      " 4   Emotion           257 non-null    object \n",
      " 5   Diary_title       159 non-null    object \n",
      " 6   Diary             257 non-null    object \n",
      " 7   label             257 non-null    float64\n",
      " 8   emotion           257 non-null    object \n",
      " 9   emotion_cause     257 non-null    object \n",
      " 10  neutral           257 non-null    float64\n",
      " 11  happy             257 non-null    float64\n",
      " 12  joy               257 non-null    float64\n",
      " 13  sadness           257 non-null    float64\n",
      " 14  anger             257 non-null    float64\n",
      " 15  worry             257 non-null    float64\n",
      " 16  dominant_emotion  257 non-null    object \n",
      " 17  dominant_score    257 non-null    float64\n",
      "dtypes: float64(9), object(9)\n",
      "memory usage: 36.3+ KB\n"
     ]
    }
   ],
   "source": [
    "diary_LLM3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f73018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Name              208 non-null    object \n",
      " 1   Number            208 non-null    object \n",
      " 2   Date              208 non-null    object \n",
      " 3   Weather           0 non-null      float64\n",
      " 4   Emotion           208 non-null    object \n",
      " 5   Diary_title       146 non-null    object \n",
      " 6   Diary             208 non-null    object \n",
      " 7   label             208 non-null    float64\n",
      " 8   emotion           208 non-null    object \n",
      " 9   emotion_cause     208 non-null    object \n",
      " 10  neutral           208 non-null    float64\n",
      " 11  happy             208 non-null    float64\n",
      " 12  joy               208 non-null    float64\n",
      " 13  sadness           208 non-null    float64\n",
      " 14  anger             208 non-null    float64\n",
      " 15  worry             208 non-null    float64\n",
      " 16  dominant_emotion  208 non-null    object \n",
      " 17  dominant_score    208 non-null    float64\n",
      "dtypes: float64(9), object(9)\n",
      "memory usage: 29.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing 'Date' -> generate emotion graph\n",
    "diary_LLM4 = diary_LLM3[diary_LLM3['Date'].notnull()]\n",
    "diary_LLM4\n",
    "diary_LLM4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10d63c",
   "metadata": {},
   "source": [
    "## Emotion Calendar - Visualization(Streamlit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce56ca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
